{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae8dd0b-97f1-4d17-8358-6de532735ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\broker\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\broker\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\broker\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\broker\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\broker\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\broker\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a3f6a5-e682-44ba-9f2e-86c446414b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FVG Backtest Results ===\n",
      "Total Trades: 0\n",
      "Winning Trades: 0\n",
      "Losing Trades: 23\n",
      "Win Rate: 0.00%\n",
      "Profit Factor: 0.00\n",
      "\n",
      "Bias Distribution:\n",
      "  2023-11-14: short\n",
      "  2023-11-15: long\n",
      "  2023-11-16: short\n",
      "  2023-11-17: short\n",
      "  2023-11-18: no trade\n",
      "  2023-11-19: no trade\n",
      "  2023-11-20: short\n",
      "  2023-11-21: long\n",
      "  2023-11-22: long\n",
      "  2023-11-23: short\n",
      "  2023-11-24: short\n",
      "  2023-11-25: no trade\n",
      "  2023-11-26: no trade\n",
      "  2023-11-27: short\n",
      "  2023-11-28: short\n",
      "  2023-11-29: long\n",
      "  2023-11-30: long\n",
      "  2023-12-01: short\n",
      "  2023-12-02: no trade\n",
      "  2023-12-03: no trade\n",
      "  2023-12-04: short\n",
      "  2023-12-05: short\n",
      "  2023-12-06: short\n",
      "  2023-12-07: long\n",
      "  2023-12-08: short\n",
      "  2023-12-09: no trade\n",
      "  2023-12-10: no trade\n",
      "  2023-12-11: short\n",
      "  2023-12-12: short\n",
      "  2023-12-13: short\n",
      "  2023-12-14: short\n",
      "  2023-12-15: long\n",
      "  2023-12-16: no trade\n",
      "  2023-12-17: no trade\n",
      "  2023-12-18: long\n",
      "  2023-12-19: short\n",
      "  2023-12-20: long\n",
      "  2023-12-21: short\n",
      "  2023-12-22: short\n",
      "  2023-12-23: no trade\n",
      "  2023-12-24: no trade\n",
      "  2023-12-25: no trade\n",
      "  2023-12-26: long\n",
      "  2023-12-27: short\n",
      "  2023-12-28: short\n",
      "  2023-12-29: long\n",
      "  2023-12-30: no trade\n",
      "  2023-12-31: no trade\n",
      "  2024-01-01: no trade\n",
      "  2024-01-02: short\n",
      "  2024-01-03: long\n",
      "  2024-01-04: short\n",
      "  2024-01-05: long\n",
      "  2024-01-06: no trade\n",
      "  2024-01-07: no trade\n",
      "  2024-01-08: long\n",
      "  2024-01-09: long\n",
      "  2024-01-10: short\n",
      "  2024-01-11: long\n",
      "  2024-01-12: long\n",
      "  2024-01-13: no trade\n",
      "  2024-01-14: no trade\n",
      "  2024-01-15: long\n",
      "  2024-01-16: long\n",
      "  2024-01-17: short\n",
      "  2024-01-18: short\n",
      "  2024-01-19: short\n",
      "  2024-01-20: no trade\n",
      "  2024-01-21: no trade\n",
      "  2024-01-22: long\n",
      "  2024-01-23: long\n",
      "  2024-01-24: short\n",
      "  2024-01-25: short\n",
      "  2024-01-26: short\n",
      "  2024-01-27: no trade\n",
      "  2024-01-28: no trade\n",
      "  2024-01-29: long\n",
      "  2024-01-30: short\n",
      "  2024-01-31: short\n",
      "  2024-02-01: short\n",
      "  2024-02-02: short\n",
      "  2024-02-03: no trade\n",
      "  2024-02-04: no trade\n",
      "  2024-02-05: long\n",
      "  2024-02-06: long\n",
      "  2024-02-07: long\n",
      "  2024-02-08: long\n",
      "  2024-02-09: long\n",
      "  2024-02-10: no trade\n",
      "  2024-02-11: no trade\n",
      "  2024-02-12: long\n",
      "  2024-02-13: short\n",
      "  2024-02-14: long\n",
      "  2024-02-15: short\n",
      "  2024-02-16: short\n",
      "  2024-02-17: no trade\n",
      "  2024-02-18: no trade\n",
      "  2024-02-19: long\n",
      "  2024-02-20: short\n",
      "  2024-02-21: long\n",
      "  2024-02-22: short\n",
      "  2024-02-23: long\n",
      "  2024-02-24: no trade\n",
      "  2024-02-25: no trade\n",
      "  2024-02-26: short\n",
      "  2024-02-27: long\n",
      "  2024-02-28: long\n",
      "  2024-02-29: short\n",
      "  2024-03-01: short\n",
      "  2024-03-02: no trade\n",
      "  2024-03-03: no trade\n",
      "  2024-03-04: long\n",
      "  2024-03-05: short\n",
      "  2024-03-06: short\n",
      "  2024-03-07: short\n",
      "  2024-03-08: short\n",
      "  2024-03-09: no trade\n",
      "  2024-03-10: no trade\n",
      "  2024-03-11: short\n",
      "  2024-03-12: short\n",
      "  2024-03-13: short\n",
      "  2024-03-14: short\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Load and prepare data\n",
    "file_path = r\"C:\\Users\\Broker\\Downloads\\eurusd.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Handle datetime conversion\n",
    "df[\"Gmt time\"] = pd.to_datetime(df[\"Gmt time\"], format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
    "df[\"PKT time\"] = df[\"Gmt time\"] + pd.Timedelta(hours=5)\n",
    "df.set_index(\"PKT time\", inplace=True)\n",
    "\n",
    "# Filter session (1 PM to 5 PM PKT)\n",
    "df[\"Hour\"] = df.index.hour\n",
    "df_session = df[(df[\"Hour\"] >= 13) & (df[\"Hour\"] < 17)].copy()\n",
    "session_groups = df_session.groupby(df_session.index.date)\n",
    "\n",
    "# Calculate Goldbach levels\n",
    "def calculate_goldbach_levels(group):\n",
    "    high = group['High'].max()\n",
    "    low = group['Low'].min()\n",
    "    range_ = high - low\n",
    "    \n",
    "    if range_ == 0:\n",
    "        return {\n",
    "            'gold_0.1': low,\n",
    "            'gold_0.2': low,\n",
    "            'gold_0.8': low,\n",
    "            'gold_0.9': low\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'gold_0.1': low + range_ * 0.1,\n",
    "        'gold_0.2': low + range_ * 0.2,\n",
    "        'gold_0.8': low + range_ * 0.8,\n",
    "        'gold_0.9': low + range_ * 0.9\n",
    "    }\n",
    "\n",
    "# Calculate AXR and ATR\n",
    "def calculate_axr_atr(group, lookback=20, atr_period=14):\n",
    "    group = group.copy()\n",
    "    \n",
    "    # Calculate ADR and AXR\n",
    "    group['High_max'] = group['High'].rolling(window=lookback, min_periods=1).max()\n",
    "    group['Low_min'] = group['Low'].rolling(window=lookback, min_periods=1).min()\n",
    "    group['ADR'] = group['High_max'] - group['Low_min']\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    group['AXR'] = np.where(\n",
    "        group['ADR'] > 0,\n",
    "        (group['Close'] - group['Low_min']) / group['ADR'],\n",
    "        0.5\n",
    "    )\n",
    "    \n",
    "    # Calculate ATR\n",
    "    group['High_low'] = group['High'] - group['Low']\n",
    "    group['High_close'] = abs(group['High'] - group['Close'].shift())\n",
    "    group['Low_close'] = abs(group['Low'] - group['Close'].shift())\n",
    "    group['TR'] = group[['High_low', 'High_close', 'Low_close']].max(axis=1)\n",
    "    group['ATR'] = group['TR'].rolling(window=atr_period, min_periods=1).mean()\n",
    "    \n",
    "    return group\n",
    "\n",
    "# Main strategy implementation\n",
    "def detect_fvg_and_backtest(group, bias):\n",
    "    trades = []\n",
    "    candles = group.copy().reset_index()\n",
    "    \n",
    "    # Validate minimum data\n",
    "    if len(candles) < 5:\n",
    "        return trades\n",
    "    \n",
    "    goldbach_levels = calculate_goldbach_levels(group)\n",
    "    group = calculate_axr_atr(group)\n",
    "    \n",
    "    for i in range(2, len(candles) - 3):\n",
    "        try:\n",
    "            c0 = candles.iloc[i-2]\n",
    "            c1 = candles.iloc[i-1]\n",
    "            c2 = candles.iloc[i]\n",
    "            \n",
    "            atr = group['ATR'].iloc[i]\n",
    "            if pd.isna(atr) or atr == 0:\n",
    "                atr = 0.0005\n",
    "            \n",
    "            # Goldbach zone check\n",
    "            in_goldbach_zone = (\n",
    "                (c0[\"High\"] <= goldbach_levels['gold_0.2'] and c2[\"Low\"] >= goldbach_levels['gold_0.1']) or\n",
    "                (c0[\"High\"] <= goldbach_levels['gold_0.9'] and c2[\"Low\"] >= goldbach_levels['gold_0.8'])\n",
    "            )\n",
    "            \n",
    "            # AXR threshold\n",
    "            axr_value = group['AXR'].iloc[i]\n",
    "            if pd.isna(axr_value):\n",
    "                axr_value = 0.5\n",
    "            \n",
    "            axr_threshold = 0.6 if bias == \"short\" else 0.4\n",
    "            axr_ok = axr_value > axr_threshold if bias == \"short\" else axr_value < axr_threshold\n",
    "            \n",
    "            # Minimum FVG size filter\n",
    "            min_fvg_size = atr * 0.3\n",
    "            fvg_size = abs(c2[\"Low\"] - c0[\"High\"]) if bias == \"short\" else abs(c0[\"Low\"] - c2[\"High\"])\n",
    "            \n",
    "            # SHORT: c0 above c2\n",
    "            if bias == \"short\" and c0[\"High\"] < c2[\"Low\"] and in_goldbach_zone and axr_ok and fvg_size >= min_fvg_size:\n",
    "                entry = c2[\"Low\"]\n",
    "                sl = max(candles.iloc[i+1][\"High\"], c2[\"High\"], c1[\"High\"])\n",
    "                \n",
    "                if sl > entry:  # Valid SL\n",
    "                    rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "                    tp = entry - rr_ratio * (sl - entry)\n",
    "                    \n",
    "                    # Check next 3 candles\n",
    "                    for j in range(i+1, min(i+4, len(candles))):\n",
    "                        high_j = candles.iloc[j][\"High\"]\n",
    "                        low_j = candles.iloc[j][\"Low\"]\n",
    "                        \n",
    "                        if high_j >= entry:\n",
    "                            if low_j <= tp:\n",
    "                                trades.append(\"win\")\n",
    "                                break\n",
    "                            elif high_j >= sl:\n",
    "                                trades.append(\"loss\")\n",
    "                                break\n",
    "            \n",
    "            # LONG: c0 below c2\n",
    "            elif bias == \"long\" and c0[\"Low\"] > c2[\"High\"] and in_goldbach_zone and axr_ok and fvg_size >= min_fvg_size:\n",
    "                entry = c2[\"High\"]\n",
    "                sl = min(candles.iloc[i+1][\"Low\"], c2[\"Low\"], c1[\"Low\"])\n",
    "                \n",
    "                if sl < entry:  # Valid SL\n",
    "                    rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "                    tp = entry + rr_ratio * (entry - sl)\n",
    "                    \n",
    "                    # Check next 3 candles\n",
    "                    for j in range(i+1, min(i+4, len(candles))):\n",
    "                        high_j = candles.iloc[j][\"High\"]\n",
    "                        low_j = candles.iloc[j][\"Low\"]\n",
    "                        \n",
    "                        if low_j <= entry:\n",
    "                            if high_j >= tp:\n",
    "                                trades.append(\"win\")\n",
    "                                break\n",
    "                            elif low_j <= sl:\n",
    "                                trades.append(\"loss\")\n",
    "                                break\n",
    "        \n",
    "        except (KeyError, IndexError, ValueError) as e:\n",
    "            continue\n",
    "    \n",
    "    return trades\n",
    "\n",
    "# Execute strategy\n",
    "bias_results = defaultdict(str)\n",
    "all_trades = []\n",
    "\n",
    "for date, group in session_groups:\n",
    "    try:\n",
    "        # Skip if insufficient data\n",
    "        if len(group) < 5:\n",
    "            continue\n",
    "        \n",
    "        # Determine bias\n",
    "        open_price = group.iloc[0][\"Open\"]\n",
    "        above_count = (group[\"High\"] > open_price).sum()\n",
    "        below_count = (group[\"Low\"] < open_price).sum()\n",
    "\n",
    "        if above_count >= 24:\n",
    "            bias = \"short\"\n",
    "        elif below_count >= 24:\n",
    "            bias = \"long\"\n",
    "        else:\n",
    "            bias = \"no trade\"\n",
    "        \n",
    "        bias_results[date] = bias\n",
    "        \n",
    "        if bias == \"no trade\":\n",
    "            continue\n",
    "        \n",
    "        trades = detect_fvg_and_backtest(group, bias)\n",
    "        all_trades.extend(trades)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date {date}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Results analysis\n",
    "results = Counter(all_trades)\n",
    "total_trades = results['win'] + results['loss'] if 'win' in results and 'loss' in results else 0\n",
    "win_rate = (results.get('win', 0) / total_trades * 100) if total_trades > 0 else 0\n",
    "profit_factor = (results.get('win', 0) / results.get('loss', 1)) if results.get('loss', 0) > 0 else 0\n",
    "\n",
    "print(\"\\n=== FVG Backtest Results ===\")\n",
    "print(f\"Total Trades: {total_trades}\")\n",
    "print(f\"Winning Trades: {results.get('win', 0)}\")\n",
    "print(f\"Losing Trades: {results.get('loss', 0)}\")\n",
    "print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "print(f\"\\nBias Distribution:\")\n",
    "for date, bias in sorted(bias_results.items()):\n",
    "    print(f\"  {date}: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698cd691-33ac-4b29-a4ca-df37bea58db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your detect_fvg_and_backtest function, replace with:\n",
    "\n",
    "def detect_fvg_and_backtest(group, bias):\n",
    "    trades = []\n",
    "    candles = group.copy().reset_index()\n",
    "    goldbach_levels = calculate_goldbach_levels(group)\n",
    "    group = calculate_axr(group)\n",
    "    \n",
    "    for i in range(2, len(candles) - 3):  # Leave room for 3-candle evaluation\n",
    "        c0, c1, c2 = candles.loc[i-2], candles.loc[i-1], candles.loc[i]\n",
    "        atr = (group['High'].rolling(14).max() - group['Low'].rolling(14).min()).iloc[i]\n",
    "        \n",
    "        # Wider Goldbach zones\n",
    "        in_goldbach_zone = (\n",
    "            (c0[\"High\"] <= goldbach_levels['gold_0.2'] and c2[\"Low\"] >= goldbach_levels['gold_0.1']) or\n",
    "            (c0[\"High\"] <= goldbach_levels['gold_0.9'] and c2[\"Low\"] >= goldbach_levels['gold_0.8'])\n",
    "        )\n",
    "        \n",
    "        # Dynamic AXR threshold\n",
    "        axr_threshold = 0.6 if bias == \"short\" else 0.4\n",
    "        axr_ok = c2['AXR'] > axr_threshold if bias == \"short\" else c2['AXR'] < axr_threshold\n",
    "        \n",
    "        if bias == \"short\" and c0[\"High\"] < c2[\"Low\"] and in_goldbach_zone and axr_ok:\n",
    "            entry = c2[\"Low\"]\n",
    "            sl = max(candles.loc[i+1][\"High\"], c2[\"High\"], c1[\"High\"])\n",
    "            rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "            tp = entry - rr_ratio * (sl - entry)\n",
    "            \n",
    "            for j in range(i+1, min(i+4, len(candles))):\n",
    "                if candles.loc[j][\"High\"] >= entry:\n",
    "                    if candles.loc[j][\"Low\"] <= tp:\n",
    "                        trades.append(\"win\")\n",
    "                        break\n",
    "                    elif candles.loc[j][\"High\"] >= sl:\n",
    "                        trades.append(\"loss\")\n",
    "                        break\n",
    "        \n",
    "        elif bias == \"long\" and c0[\"Low\"] > c2[\"High\"] and in_goldbach_zone and axr_ok:\n",
    "            entry = c2[\"High\"]\n",
    "            sl = min(candles.loc[i+1][\"Low\"], c2[\"Low\"], c1[\"Low\"])\n",
    "            rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "            tp = entry + rr_ratio * (entry - sl)\n",
    "            \n",
    "            for j in range(i+1, min(i+4, len(candles))):\n",
    "                if candles.loc[j][\"Low\"] <= entry:\n",
    "                    if candles.loc[j][\"High\"] >= tp:\n",
    "                        trades.append(\"win\")\n",
    "                        break\n",
    "                    elif candles.loc[j][\"Low\"] <= sl:\n",
    "                        trades.append(\"loss\")\n",
    "                        break\n",
    "    \n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50952c8f-0ddb-4d4d-b06c-248633bea5fc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AXR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AXR'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 122\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno trade\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     trades \u001b[38;5;241m=\u001b[39m detect_fvg_and_backtest(group, bias)\n\u001b[0;32m    123\u001b[0m     all_trades\u001b[38;5;241m.\u001b[39mextend(trades)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Results analysis\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m, in \u001b[0;36mdetect_fvg_and_backtest\u001b[1;34m(group, bias)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Dynamic AXR threshold\u001b[39;00m\n\u001b[0;32m     61\u001b[0m axr_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.4\u001b[39m\n\u001b[1;32m---> 62\u001b[0m axr_ok \u001b[38;5;241m=\u001b[39m c2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAXR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m axr_threshold \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m c2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAXR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m axr_threshold\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Minimum FVG size filter\u001b[39;00m\n\u001b[0;32m     65\u001b[0m min_fvg_size \u001b[38;5;241m=\u001b[39m atr \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'AXR'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Load and prepare data\n",
    "file_path = r\"C:\\Users\\Broker\\Downloads\\eurusd.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"Gmt time\"] = pd.to_datetime(df[\"Gmt time\"], format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
    "df[\"PKT time\"] = df[\"Gmt time\"] + pd.Timedelta(hours=5)\n",
    "df.set_index(\"PKT time\", inplace=True)\n",
    "\n",
    "# Filter session (1 PM to 5 PM PKT)\n",
    "df[\"Hour\"] = df.index.hour\n",
    "df_session = df[(df[\"Hour\"] >= 13) & (df[\"Hour\"] < 17)].copy()\n",
    "session_groups = df_session.groupby(df_session.index.date)\n",
    "\n",
    "# Calculate Goldbach levels (PO3 27)\n",
    "def calculate_goldbach_levels(group):\n",
    "    high = group['High'].max()\n",
    "    low = group['Low'].min()\n",
    "    range_ = high - low\n",
    "    \n",
    "    return {\n",
    "        'gold_0.1': low + range_ * 0.1,\n",
    "        'gold_0.2': low + range_ * 0.2,\n",
    "        'gold_0.8': low + range_ * 0.8,\n",
    "        'gold_0.9': low + range_ * 0.9\n",
    "    }\n",
    "\n",
    "# Calculate AXR (20-period lookback) and ADR\n",
    "def calculate_axr_adr(group, lookback=20):\n",
    "    group['ADR'] = group['High'].rolling(lookback).max() - group['Low'].rolling(lookback).min()\n",
    "    group['AXR'] = (group['Close'] - group['Low'].rolling(lookback).min()) / group['ADR']\n",
    "    group['ATR'] = group['High'].rolling(14).max() - group['Low'].rolling(14).min()\n",
    "    return group\n",
    "\n",
    "# Main strategy implementation\n",
    "def detect_fvg_and_backtest(group, bias):\n",
    "    trades = []\n",
    "    candles = group.copy()\n",
    "    candles = candles.reset_index()  # Convert index to column\n",
    "    goldbach_levels = calculate_goldbach_levels(group)\n",
    "    group = calculate_axr_adr(group)\n",
    "    \n",
    "    for i in range(2, len(candles) - 3):\n",
    "        c0, c1, c2 = candles.iloc[i-2], candles.iloc[i-1], candles.iloc[i]\n",
    "        atr = group['ATR'].iloc[i]\n",
    "        \n",
    "        # Get time correctly from the datetime column\n",
    "        current_time = candles.iloc[i]['PKT time']\n",
    "        if current_time.hour > 15:  # After 3PM PKT\n",
    "            continue\n",
    "            \n",
    "        # Wider Goldbach zones\n",
    "        in_goldbach_zone = (\n",
    "            (c0[\"High\"] <= goldbach_levels['gold_0.2'] and c2[\"Low\"] >= goldbach_levels['gold_0.1']) or\n",
    "            (c0[\"High\"] <= goldbach_levels['gold_0.9'] and c2[\"Low\"] >= goldbach_levels['gold_0.8'])\n",
    "        )\n",
    "        \n",
    "        # Dynamic AXR threshold\n",
    "        axr_threshold = 0.6 if bias == \"short\" else 0.4\n",
    "        axr_ok = c2['AXR'] > axr_threshold if bias == \"short\" else c2['AXR'] < axr_threshold\n",
    "        \n",
    "        # Minimum FVG size filter\n",
    "        min_fvg_size = atr * 0.3\n",
    "        fvg_size = c2[\"Low\"] - c0[\"High\"] if bias == \"short\" else c0[\"Low\"] - c2[\"High\"]\n",
    "        \n",
    "        if bias == \"short\" and c0[\"High\"] < c2[\"Low\"] and in_goldbach_zone and axr_ok and fvg_size >= min_fvg_size:\n",
    "            entry = c2[\"Low\"]\n",
    "            sl = max(candles.iloc[i+1][\"High\"], c2[\"High\"], c1[\"High\"])\n",
    "            rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "            tp = entry - rr_ratio * (sl - entry)\n",
    "            \n",
    "            for j in range(i+1, min(i+4, len(candles))):\n",
    "                if candles.iloc[j][\"High\"] >= entry:\n",
    "                    if candles.iloc[j][\"Low\"] <= tp:\n",
    "                        trades.append(\"win\")\n",
    "                        break\n",
    "                    elif candles.iloc[j][\"High\"] >= sl:\n",
    "                        trades.append(\"loss\")\n",
    "                        break\n",
    "        \n",
    "        elif bias == \"long\" and c0[\"Low\"] > c2[\"High\"] and in_goldbach_zone and axr_ok and fvg_size >= min_fvg_size:\n",
    "            entry = c2[\"High\"]\n",
    "            sl = min(candles.iloc[i+1][\"Low\"], c2[\"Low\"], c1[\"Low\"])\n",
    "            rr_ratio = 2.5 if atr > 0.0015 else 3.5\n",
    "            tp = entry + rr_ratio * (entry - sl)\n",
    "            \n",
    "            for j in range(i+1, min(i+4, len(candles))):\n",
    "                if candles.iloc[j][\"Low\"] <= entry:\n",
    "                    if candles.iloc[j][\"High\"] >= tp:\n",
    "                        trades.append(\"win\")\n",
    "                        break\n",
    "                    elif candles.iloc[j][\"Low\"] <= sl:\n",
    "                        trades.append(\"loss\")\n",
    "                        break\n",
    "    \n",
    "    return trades\n",
    "\n",
    "# Execute strategy\n",
    "bias_results = defaultdict(str)\n",
    "all_trades = []\n",
    "\n",
    "for date, group in session_groups:\n",
    "    # Determine bias\n",
    "    open_price = group.iloc[0][\"Open\"]\n",
    "    above_count = (group[\"High\"] > open_price).sum()\n",
    "    below_count = (group[\"Low\"] < open_price).sum()\n",
    "\n",
    "    if above_count >= 24:\n",
    "        bias = \"short\"\n",
    "    elif below_count >= 24:\n",
    "        bias = \"long\"\n",
    "    else:\n",
    "        bias = \"no trade\"\n",
    "    \n",
    "    bias_results[date] = bias\n",
    "    \n",
    "    if bias == \"no trade\":\n",
    "        continue\n",
    "    \n",
    "    trades = detect_fvg_and_backtest(group, bias)\n",
    "    all_trades.extend(trades)\n",
    "\n",
    "# Results analysis\n",
    "results = Counter(all_trades)\n",
    "total_trades = results['win'] + results['loss'] if 'win' in results and 'loss' in results else 0\n",
    "win_rate = results['win'] / total_trades * 100 if total_trades > 0 else 0\n",
    "\n",
    "print(\"\\n=== Backtest Results ===\")\n",
    "print(f\"Total Trades: {total_trades}\")\n",
    "print(f\"Winning Trades: {results.get('win', 0)}\")\n",
    "print(f\"Losing Trades: {results.get('loss', 0)}\")\n",
    "print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "print(f\"Profit Factor: {results.get('win', 0)/results.get('loss', 1):.2f}\" if results.get('loss', 0) > 0 else 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de68b9-d287-4363-bb0b-e1c4f5afd305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
